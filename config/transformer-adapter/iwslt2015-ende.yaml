Annotation:
  device: v1002-2
  language: en-de
  dataset: iwslt2015 en-de, clean 80, bpe 32k, vocab 35k
  what: transformer, 
  hyper_parameter: 
  log_file: 

Dataset:
  train_dataset_path:
    - "/home/zhengx/data/adapter_dataset/iwslt2015-ende-share/IWSLT15.TED.train2015.en-de.tsv" # bpe size 32000
    # - "/home/zhengx/data/adapter_dataset/medical-ende-share/train.tsv"
    # - "/home/zhengx/data/adapter_dataset/laws-ende-share/train.tsv"
    # - "/home/zhengx/data/adapter_dataset/education-ende-share/train.tsv"

  dev_dataset_path:
    - "/home/zhengx/data/adapter_dataset/iwslt2015-ende-share/IWSLT15.TED.tst2012.en-de.tsv"

  test_dataset_path:
    - "/home/zhengx/data/adapter_dataset/iwslt2015-ende-share/IWSLT15.TED.tst2013.en-de.tsv"
    - "/home/zhengx/data/adapter_dataset/iwslt2015-ende-share/IWSLT15.TED.tst2014.en-de.tsv"

  target_language: de
  detruecase_script: /home/user_data55/zhengx/project/DomainAdaptationForTranslation/scripts/recaser/detruecase.perl
  detokenize_script: /home/user_data55/zhengx/project/DomainAdaptationForTranslation/scripts/tokenizer/detokenizer.perl
  combine_train_datasets: True
  filter_len: 150

Vocab:
  use_bpe: True
  src:
    file: "/home/zhengx/data/adapter_dataset/iwslt2015-ende-share/vocab.en"
    max_size: 36000
  trg:
    file: "/home/zhengx/data/adapter_dataset/iwslt2015-ende-share/vocab.de"
    max_size: 36000

Model:
  feature_size: 512
  feedforward_dim: 2048
  head_num: 8
  dropout_rate: 0.1
  num_layers: 6
  share_embedding: False
  adapter_domains: ['iwslt']
  adapter_bottleneck_size: 512

Optimizer:
  factor: 2.0
  warmup_step: 8000
  grad_clip: 0.0


Train:
  current_domain: iwslt
  update_batch_count: 1

  load_exist_model: True # load model
  model_load_path: /home/zhengx/model_save/iwslt2015-ende/adapter-metalearning-2/model/best_model

  load_optimizer: False  # load model and optimizer
  optimizer_path: 

  batch_size: 8192

  epoch_num: 500
  validation_per_steps: 2000

Validation:
  ref: /home/zhengx/data/adapter_dataset/iwslt2015-ende-share/IWSLT15.TED.tst2012.en-de.de
  option: [loss, bleu]
  Decoding:
    beam_size: 4
    max_steps: 120

  batch_size: 64
  Bleu:
    gram: 4
    level: word

Test:
  domain: iwslt
  refs: [
    /home/zhengx/data/adapter_dataset/iwslt2015-ende-share/IWSLT15.TED.tst2013.en-de.de,
    /home/zhengx/data/adapter_dataset/iwslt2015-ende-share/IWSLT15.TED.tst2014.en-de.de
  ]
  batch_size: 64
  tag: translation
  Decoding:
    beam_size: 4
    max_steps: 100
  # parameter as validation
  model_path: /home/zhengx/model_save/iwslt2015-ende/metalearning-finetune/model/best_model
  output_path:
    - "/home/zhengx/output/iwslt-2015/13.output"
    - "/home/zhengx/output/iwslt-2015/14.output"
    # - "/home/zhengx/output/Education-Laws-deen-label/laws.output"
    # - "../data/finetune-ende/nc-devtest2007.output"

Record:
  path: "/home/user_data55/zhengx/project/record-new/iwslt2015-ende/metalearning-finetune"
  model_record_path: /home/zhengx/model_save/iwslt2015-ende/metalearning-finetune
