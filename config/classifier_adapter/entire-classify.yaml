Annotation:
  device: 2080ti1
  language: en-de
  dataset: wmt2014, iwslt, books, bible, laws, medical
  what: transformer, classify
  hyper_parameter: 
  log_file: 

Dataset:
  train_dataset_path:
    - /home/zhengx/data/wmt2014-ende-share/train-small.tsv  # news 300000
    - /home/zhengx/data/wmt14_adapt_dataset_share/iwslt2015/train2015.tsv  # iwslt
    - /home/zhengx/data/wmt14_adapt_dataset_share/books/books-train.tsv  # books
    - /home/zhengx/data/wmt14_adapt_dataset_share/bible-clean/bible-train.tsv  # bible
    - /home/zhengx/data/wmt14_adapt_dataset_share/laws-clean/laws-train.tsv  # laws
    - /home/zhengx/data/wmt14_adapt_dataset_share/medical-clean/medical-train.tsv  # medical
  train_dataset_domain: [news, iwslt, books, bible, laws, medical]

  dev_dataset_path:
    # - /home/zhengx/data/wmt2014-ende-share/newstest2013.tsv
    - /home/zhengx/data/wmt14_adapt_dataset_share/iwslt2015/tst2012.tsv
    - /home/zhengx/data/wmt14_adapt_dataset_share/books/books-dev.tsv
    - /home/zhengx/data/wmt14_adapt_dataset_share/bible-clean/bible-dev.tsv
    - /home/zhengx/data/wmt14_adapt_dataset_share/laws-clean/laws-dev.tsv
    - /home/zhengx/data/wmt14_adapt_dataset_share/medical-clean/medical-dev.tsv
  dev_dataset_domain: [iwslt, books, bible, laws, medical]

  test_dataset_path:
    # - "/home/zhengx/data/wmt2014-ende-share/newstest2013.tsv"
    - "/home/zhengx/data/wmt2014-ende-share/newstest2014.tsv"
  
  combine_train_datasets: False
  filter_len: 200

Vocab:
  use_bpe: True
  share_bpe:
  src:
    file: /home/zhengx/data/wmt2014-ende-share/vocab
    max_size: 37000
  trg:
    file: /home/zhengx/data/wmt2014-ende-share/vocab
    max_size: 37000

Model:
  feature_size: 512
  feedforward_dim: 2048
  head_num: 8
  dropout_rate: 0.1
  num_layers: 6
  layer_norm_rescale: True

  share_enc_dec_embedding: True
  share_decoder_embedding: True

  # generator
  generator_bias: False

  classifier_type: simple
  classify_feature_size: 128
  domain_class_num: 10
  domain_mask: [1, 1, 1, 1, 1, 1, 0, 0, 0, 0]
  domain_dict: {
    'news': 0,
    'iwslt': 1,
    'books': 2,
    'bible': 3,
    'laws': 4,
    'medical': 5,
  }
  domain_adapter_dict: {
    'iwslt': {
      'memory_count': 256
    },
    'books': {
      'memory_count': 512
    },
    'bible': {
      'memory_count': 512
    },
    'laws': {
      'memory_count': 1024
    },
    'medical': {
      'memory_count': 1024
    },
  }

Criterion:
  name: cross_entropy
  # name: nll
  # label_smoothing: 0.1
  # reduction: mean

  # name: kl_divergence
  # label_smoothing: 0.1
  # reduction: sum

Optimizer:
  beta2: 0.998
  lr_rate: 3.0e-4
  lr_scheduler:
    name: reduce_lr_on_loss
    factor: 0.5
    patience: 5
    min_lr: 3.0e-5
  grad_clip: 5.0

Train:
  stage: classify
  use_multiple_gpu: False

  random_seed: 1234
  load_exist_model: True # load model
  model_load_path: /home/zhengx/model_save/wmt2014-ende/6000-4/loss_best_model
  # model_load_path: /home/zhengx/model_save/entire-ende/no_layer_norm_rescale/bleu_best/model
  load_optimizer: False  # load model and optimizer
  optimizer_path: 
  load_lr_scheduler: False
  lr_scheduler_path: 

  batch_size: 8192
  update_batch_count: 1
  epoch_num: 50

Validation:
  
  batch_size: 64

  loss_validation:
    start_on_steps: 1000
    frequency: 500

Test:

  refs: [
    # /home/zhengx/data/wmt2014-ende-share/newstest2013.de,
    /home/zhengx/data/wmt2014-ende-share/newstest2014.de
  ]
  
  # model_path: /home/zhengx/model_save/wmt14-ende/no_layer_norm_rescale/loss_best/model
  model_path: /home/zhengx/model_save/wmt2014-ende/6000-4/loss_best_model
  # model_path: /home/zhengx/model_save/wmt14-ende/no_layer_norm_rescale_inverse_sqrt/loss_best/model
  save_in_multi_gpu: False
  
  output_path:
    # - "/home/zhengx/output/wmt2014-ende/newstest2013.output"
    - "/home/zhengx/output/wmt2014-ende/newstest2014.output"


Record:
  training_record_path: /home/user_data55/zhengx/record/classify/entire-simple
  
  model_record:
    path: /home/zhengx/model_save/classify/entire-simple
    best_model_save:
      loss_best: True
      save_optimizer: False
      save_lr_scheduler: False
    
    # save last checkpoint
    last_checkpoint_save:
      start_on_steps: 50000
      frequency: 2000
      save_optimizer: False
      save_lr_scheduler: False
      save_checkpoint_count: 0

visualize_file: /home/zhengx/visualize/wmt14_adapt/news
